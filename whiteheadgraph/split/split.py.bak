import copy
import word
import whiteheadgraph.build.wgraph as wg
import whiteheadgraph.build.orderedmultigraph as omg
import networkx as nx
import partition as part
import whiteheadgraph.build.whiteheadreduce as wreduce
import AutF

def splitsFreely(wgraphorwords):
    """
    Decide if Whitehead graph splits freely.
    """
    W, wordlist=wg.wgparse(wgraphorwords)
    return wreduce.WhiteheadMinimize(W,justtellmeitbecomesdisconnected=True)

def getFreeSplitting(wgraphorwords, rank, withwordmaps=False):
    """
    Find canonical maximal free splitting of free group of given rank relative to words.
    """
    minimization=wreduce.WhiteheadMinimize(wgraphorwords)
    simplifiedwordlist,simpmap=wg.simplifyWordlist(minimzation['wordlist'],withmap=True)

    # words in simplifiedwordlist generate disctinct conjugacy classes of maximal cyclic subgroups
    # furthermore, since the list is Whitehead minimal we can use these words to parition generators to get the free splitting


    wordgens=[set([abs(i) for i in w.letters]) for w in simplifiedwordlist]
    wordgens.extend([set([i]) for i in range(1,rank+1)]) # add singleton sets to make sure generators that don't appear in any words are included
    thepartition=part.makePartition(*wordgens)
    # thepartition is a list of disjoint subsets of generators of the free group, but not in the original basis
    # to get the answer in terms of the original basis need to apply inverse sequence of whitehead automorphisms

    inverseminimizer=AutF.product(*[waut.inverse() for waut in reversed(minimization['whiteheadsequence'])])
    return [set([inverseminimizer(word.word([i])) for i in p]) for p in thepartition.parts]
    
    ###############  need to define graphs of groups etc...
    
    
def givesCut(W,w,returnnumbercomponents=False):
    """
    Check if endpoints of word w give cut point/pair in decomposition space for Whitehead graph W.
    """
    assert(W.isConnected())
    assert(not any([W.isCutVertex(v) for v in W]))
    # We require that W is connected without cut vertices.
    
    w=word.cyclicReduce(w)
    if len(w)==0:
        return False
    else:
        prefixw=word.word(w.letters[0:len(w)-1])
        G=wg.wgrowWord(W,prefixw)
        v1=tuple(w.letters)
        v2=(-w.letters[-1],)
        # G is a generalized whitehead graph. The w action will identify vertices v1 and v2.
        # G-{v1,v2} is a findamental domain for the action of w on the infinte whitehead graph over <w>.
        # We can compute the number of complementary components of this infinte whitehead graph by understanding how the splicemap interacts with connected components of the finite whitehead graph.
        
        components=G.connectedComponentsMinusTwoVertices(v2,v1)
        edgelist1=[[e for e in range(0, G.valence(v1)) if G.oppositeEnd(G.edgeOrder(v1)[e],v1) in components[i]] for i in range(0,len(components))] # edgelist1[k] is list of loose edges at v1 that connected to vertices in component k
        edgelist2=[[e for e in range(0, G.valence(v2)) if G.oppositeEnd(G.edgeOrder(v2)[e],v2) in components[i]] for i in range(0,len(components))]      # edgelist2[k] is list of loose edges at v2 that connected to vertices in component k             
        missededges=set(G.incidentEdges(v1))-set.union(*[set([G.edgeOrder(v1)[e] for e in p]) for p in edgelist1]) # edges that go directly between v1 and v2
        while missededges!=set([]):
            nextedge=missededges.pop()
            edgelist1+=[[G.edgeOrder(v1).index(nextedge)]]
            edgelist2+=[[G.edgeOrder(v2).index(nextedge)]]
        P1=part.Partition(edgelist1)
        P2=part.Partition(edgelist2)
        partitionmap=range(0,len(P1.parts))
        splicemap=W.splicemaps[w.letters[-1]]
        (newP1,newP2)=part.compatibleCoarsenings(P1,P2,partitionmap,splicemap)
        numberofcomponents=len(newP1.parts)-word.isConjugateInto(w,*W.wordlist) # If w is conjugate into the wordlist then one part of the partition does not correspond to a component, just a segregated edge.
        if returnnumbercomponents:
            return numberofcomponents
        else:
            return bool(numberofcomponents -1)

        

def numberComplementaryComponents(W,w):
    """
    Find numberof complementary components of <w> in W
    """
    return givesCut(W,w,returnnumbercomponents=True)

def findCutPoints(W):
    """
    Return list of reperesentatives of the cut points.
    """
    # every cut point is stabilized by a conjugate of one of the generating words, so just check if they give cuts.
    cutpoints=[]
    for word in W.wordlist:
        if givesCut(W,word):
            cutpoints+=[word]
    return cutpoints

def crossingCutPairs(W,w1,w2):
    """
    Decide if w1 and w1 give crossing cut pairs for W.
    """
    w1=word.cyclicReduce(w1)
    w2=word.cyclicReduce(w2)
    if not numberComplementaryComponents(W,w1)==2 and numberComplementaryComponents(W,w2)==2: # First check if they are even cut pairs.
        return False
    else:
        return not givesCut(wg.WGraph(W.wordlist+[w1]),w2) # If they cross and we add one of them to the wordlist then the second word no longer gives a cut.

def givesSplitting(W,w):
    """
    Decide if W splits over <w>.
    """
    return givesCut(W,w) and not crossingCutPairs(W,w,w) # <w> gives a splitting if it gives a cut and it doesn't cross itself.



    
def pushForwardPartition(W,v0,P0,v1):
    """
    Find partitions newP0 of of v0 edges and P1 of v1 edges compatible with P0 and connectivity in W-{v0,v1}
    """
    assert(v0!=v1)
    components=W.connectedComponentsMinusTwoVertices(v0,v1)
    newgraph=nx.Graph()
    for c in components:
        newgraph.add_star([(n,'vert') for n in c])
    for p in P0.parts:
        newgraph.add_star([(e,'edge0') for e in p])
    for i in range(W.valence(v1)):
        if W.oppositeEnd(W.incidentEdges(v1)[i],v1)==v0:
            newgraph.add_edge((i,'edge1'),(W.incidentEdges(v0).index(W.incidentEdges(v1)[i]),'edge0'))
        else:
            newgraph.add_edge((i,'edge1'),(W.oppositeEnd(W.incidentEdges(v1)[i],v1),'vert'))
    for i in range(W.valence(v0)):
        if W.oppositeEnd(W.incidentEdges(v0)[i],v0)!=v1:
            newgraph.add_edge((i,'edge0'),(W.oppositeEnd(W.incidentEdges(v0)[i],v0),'vert'))
    newcomponents=nx.connected_components(newgraph)
    edgelist0=[]
    edgelist1=[]
    for i in range(len(newcomponents)):
        part0=[]
        part1=[]
        for n in newcomponents[i]:
            if n[1]=='edge0':
                part0+=[n[0]]
            if n[1]=='edge1':
                part1+=[n[0]]
        edgelist0+=[part0]
        edgelist1+=[part1]
    newP0=part.Partition(edgelist0)
    part0coarseningmap=[]
    for i in range(len(P0.parts)):
        e=P0.parts[i].pop()
        P0.parts[i].add(e)
        part0coarseningmap+=[newP0.whichPart(e)]
    return (part0coarseningmap, newP0 , part.Partition(edgelist1))
            

def extendSM(W,SM,buds,directions,maxlength=None):
    """
    Recursively extend finite state machine holding edge partitions.
    """
    # buds are the nexly added states that we still need to compute outgoing edges
    # newbuds will be the buds in the next iteration
    # maxlength is bound on number of steps to extend the state machine from the original states
    newbuds=set({})
    while buds:
        thisbud=buds.pop()
        indirec=thisbud[0]
        inpart=thisbud[1]
        for outdirec in directions:
            if outdirec!=indirec: # don't backtrack
                (coarseningmap,coarsenedinpart,outpart)=pushForwardPartition(W,indirec,inpart,outdirec)
                if len(outpart.parts)>1: # only keep going if we potentially have more than one component in this direction
                    newindirec=-outdirec
                    newinpartslist=[[] for i in range(len(outpart.parts))]
                    for i in range(W.valence(newindirec)):
                        newinpartslist[outpart.whichPart(W.splicemaps[newindirec][i])]+=[i]
                    newinpart=part.Partition(newinpartslist)
                    newbud=(newindirec,newinpart)
                    # check if newbud is already in SM
                    for n in SM:
                        if newbud[0]==n[0]:
                            if part.isReorderedPartition(newbud[1],n[1]): # newbud is already in SM, so don't add a new vertex
                                SM.add_edge(thisbud,n)#,{'label':outdirec,'coarseningmap':newcoarseningmap})
                                break
                    else: # newbud is a new node.
                        SM.add_node(newbud)
                        SM.add_edge(thisbud,newbud)#,{'label':outdirec,'coarseningmap':coarseningmap})
                        newbuds.add(newbud)
    # we have now extended all the original buds, but if we created new vertices we need to recurse.
    buds.update(newbuds)
    if buds:
        if maxlength==None:
            extendSM(W,SM,buds,directions,maxlength)
        elif maxlength>0:
            extendSM(W,SM,buds,directions,maxlength-1)
    
    

def findCutPairs(W,maxlength=None):
    """
    Find cut pairs for a whitehead graph.
    """
    wordlist=W.wordlist
    rank=word.guessRank(*wordlist)
    directions=range(-rank,rank+1)
    directions.remove(0)
    buds=set({})
    SM=nx.DiGraph()
    # SM is a finite state machine.
    # Nodes correspond to free group generator with partition of edges of Whitehead graph crossing that edge in cayley tree.
    # Edges correspond to a legal turn in the free group, together with a coarsening map of partitions coming from connectivity in the Whitehead graph.
    # If we find a loop in the state machine so that the partitions have more than one part then we have found a cut word.
    # Buds are newly added nodes that need to have outgoing edges computed.
    for urvert in range(-rank,0):
        urpart=part.Partition([[i] for i in range(W.valence(urvert))])
        SM.add_node((urvert, urpart))
        buds.add((urvert, urpart))
    extendSM(W,SM,buds,directions,maxlength)
    cycles=nx.simple_cycles(SM) # get the simple cycles in the state machine.
    cutpoints=set([])
    uncrossed=set([])
    othercuts=set([])
    for cycle in cycles:
        thewordletters=[]
        for i in range(1,len(cycle)): # read off the word of the free group from the cycle in the state machine
            thewordletters+=[-cycle[i][0]]
        theword=word.word(thewordletters)
        wordinlist=word.isConjugateInto(theword,*wordlist) # see if theword is in the generating wordlist
        complementarycomponents=len(cycle[0][1].parts)-wordinlist # if theword is in the wordlist then one component is just the word itself and not a complementary component
        if wordinlist and complementarycomponents>1:
            cutpoints.add(theword)
        elif complementarycomponents>2:
            uncrossed.add(theword)
        elif complementarycomponents>1:
            othercuts.add(theword) # for two components we can't tell immediatedly whether it is crossed or uncrossed

    # It is possible that the state machine contains different loops that read off the same word, just with different partitions. In partitcular, we could have a word for an uncrossed cut pair that also appears as a loop in the state machine with 2-part partitions. We should not include this word in both the 'uncrossed' list and the 'othercuts' list.
    reducedcutpoints=set(wg.simplifyWordlist(cutpoints))
    reduceduncrossed=set(wg.simplifyWordlist(uncrossed,reducedcutpoints))
    reducedothercuts=set(wg.simplifyWordlist(othercuts,set.union(reducedcutpoints,reduceduncrossed)))
    if buds:
        areyousurethatsall=False # If there are still buds that means we reached maxlength and didn't finish building the state machine. If we found some cuts, great. If not it may be because we didn't look hard enough.
    else:
        areyousurethatsall=True
    return ({'cutpoints':reducedcutpoints,'uncrossed':reduceduncrossed,'othercuts':reducedothercuts},areyousurethatsall)
        


def isRigid(originalW, maxlength=None):
    """
    Decide if W is rigid.
    """
    W=wg.WGraph(wreduce.WhiteheadMinimize(originalW)['wordlist'])
    if not W.isConnected():
        return False
    elif W.isCircle():
        return False
    elif findCutPoints(W):
        return False
    else:
        (cuts,areyousurethatsall)=findCutPairs(W,maxlength)
        if set.union(cuts['cutpoints'],cuts['uncrossed'],cuts['othercuts']): # if we found any cuts
            return False
        else: # we didn't find any cuts
            if areyousurethatsall: # and the state machine was complete, so we're sure there really are no cuts
                return True
            else: # otherwise we quit looking because the state machine got too big, so we can't be sure that there are really no cuts
                return None
    

   
        

            
        
        


    
    

